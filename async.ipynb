{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastapi import FastAPI\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "import httpx\n",
    "app = FastAPI()\n",
    "\n",
    "\n",
    "urls = [\n",
    "    'https://en.wikipedia.org/wiki/Web_scraping',\n",
    "    'https://en.wikipedia.org/wiki/Python_(programming_language)',\n",
    "    'https://en.wikipedia.org/wiki/Threading_(computer_science)'\n",
    "]\n",
    "\n",
    "async def scrape(url):\n",
    "    print(f\"Started scraping {url} at {time.strftime('%H:%M:%S')}\")\n",
    "    async with httpx.AsyncClient() as client:\n",
    "        response = await client.get(url)\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    title = soup.title.string\n",
    "    print(f\"Finished scraping {url} - Title: {title} at {time.strftime('%H:%M:%S')}\")\n",
    "\n",
    "@app.post(\"/scrape/\")\n",
    "async def scrape_wikipedia():\n",
    "    # Use Python's asyncio to gather tasks and run them concurrently\n",
    "    await asyncio.gather(*(scrape(url) for url in urls))\n",
    "    return {\"status\": \"Scraping completed for Wikipedia pages.\"}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
